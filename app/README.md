# RAG Stock Sentiment Analysis

Eine FastAPI-Anwendung zur Analyse von Aktien-Sentiment basierend auf Reddit-Posts mit RAG (Retrieval-Augmented Generation).

## ğŸ—ï¸ Projektstruktur

```
app/
â”œâ”€â”€ api/                    # API-Endpunkte
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ routes.py          # FastAPI Router
â”œâ”€â”€ data/                   # Datenverarbeitung
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ reddit_client.py   # Reddit API Client
â”œâ”€â”€ embedding/              # Embedding-Verarbeitung
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ embed_posts.py     # Embedding-Generierung
â”œâ”€â”€ llm/                    # LLM-Integration
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ generator.py       # OpenAI Integration
â”œâ”€â”€ rag/                    # RAG-System
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ query_engine.py    # RAG Query Engine
â”œâ”€â”€ vector_store/           # Vector Store
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ client.py          # Qdrant Client
â”œâ”€â”€ utils/                  # Hilfsfunktionen
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ datetime_utils.py  # Datum/Zeit Utilities
â”‚   â””â”€â”€ file_utils.py      # Datei-Utilities
â”œâ”€â”€ templates/              # HTML Templates
â”‚   â””â”€â”€ index.html         # Web Interface
â””â”€â”€ main.py                # FastAPI App

scripts/                   # AusfÃ¼hrbare Scripts
â”œâ”€â”€ collect_reddit_data.py # Reddit-Daten sammeln
â”œâ”€â”€ process_embeddings.py  # Embeddings verarbeiten
â””â”€â”€ query_rag.py          # RAG-Abfragen

data/                      # Datenverzeichnis
â”œâ”€â”€ processed/
â”‚   â”œâ”€â”€ csv/              # Reddit-Daten als CSV
â”‚   â””â”€â”€ npy/              # Embeddings als NumPy Arrays
```

## ğŸš€ Schnellstart

### 1. API starten

```bash
# Von Root-Verzeichnis
uvicorn app.main:app --reload

# Oder von app-Verzeichnis
cd app
uvicorn main:app --reload
```

### 2. Web-Interface Ã¶ffnen

http://127.0.0.1:8000

### 3. Qdrant Server starten

```bash
docker run -p 6333:6333 qdrant/qdrant
```

## ğŸ“‹ API-Endpunkte

- `GET /` - Web-Interface fÃ¼r Stock Sentiment Analysis
- `POST /api/collect-data` - Startet Daten-Sammlung fÃ¼r eine Aktie
- `GET /api/pipeline-status/{collection_name}` - Pipeline-Status abfragen
- `POST /api/query` - RAG-Abfrage fÃ¼r Stock Sentiment
- `GET /api/collections` - VerfÃ¼gbare Datensammlungen auflisten

## ğŸ› ï¸ Scripts verwenden

### Reddit-Daten sammeln

```bash
python scripts/collect_reddit_data.py AAPL --limit 100
python scripts/collect_reddit_data.py TSLA --query "Tesla earnings" --limit 50
```

### Embeddings verarbeiten

```bash
# VerfÃ¼gbare Datasets auflisten
python scripts/process_embeddings.py --list-available

# Embeddings fÃ¼r Dataset verarbeiten
python scripts/process_embeddings.py aapl_20241201_143022
```

### RAG-Abfragen

```bash
python scripts/query_rag.py "What is the sentiment around Tesla?" --collection tesla_20241201_143022 --show-context
```

## ğŸ“Š Verwendungsbeispiel

### 1. Daten sammeln

```bash
# Ãœber Web-Interface oder API
curl -X POST "http://localhost:8000/api/collect-data" \
  -H "Content-Type: application/json" \
  -d '{
    "stock_symbol": "TSLA",
    "search_query": "Tesla earnings",
    "limit": 50
  }'
```

### 2. Sentiment abfragen

```bash
curl -X POST "http://localhost:8000/api/query" \
  -H "Content-Type: application/json" \
  -d '{
    "stock_symbol": "TSLA",
    "question": "What is the sentiment around Tesla'\''s recent earnings?",
    "top_k": 5
  }'
```

## ğŸ›ï¸ Architektur

```mermaid
graph TD
    subgraph Frontend
        A["index.html<br/>(Web UI)"]
    end
    subgraph FastAPI Backend
        B["main.py<br/>(FastAPI App)"]
        C["api/routes.py<br/>(API Endpoints)"]
        D["data/reddit_client.py<br/>(Reddit Fetch)"]
        E["embedding/embed_posts.py<br/>(Embeddings)"]
        F["vector_store/client.py<br/>(Qdrant Upload)"]
        G["rag/query_engine.py<br/>(RAG)"]
        H["llm/generator.py<br/>(LLM)"]
    end
    subgraph External Services
        I["Reddit API"]
        J["Qdrant<br/>(Vector DB)"]
        K["OpenAI API<br/>(LLM)"]
    end

    A -- HTTP (Form/API) --> B
    B -- include_router --> C
    C -- collect-data --> D
    D -- fetches --> I
    D -- saves CSV --> E
    E -- generates embeddings --> F
    F -- uploads vectors --> J
    C -- query --> G
    G -- search vectors --> J
    G -- calls LLM --> H
    H -- OpenAI API --> K
    G -- returns answer --> C
    C -- API Response --> A
```

## ğŸ”§ Konfiguration

### Umgebungsvariablen (.env)

```bash
# Reddit API
REDDIT_CLIENT_ID=your_client_id
REDDIT_CLIENT_SECRET=your_client_secret
REDDIT_USER_AGENT=your_user_agent

# OpenAI API
OPENAI_API_KEY=your_openai_api_key
```

## ğŸ›‘ App beenden

```bash
# Port 8000 finden und beenden
lsof -i :8000
kill -9 <PID>

# Oder alle uvicorn Prozesse beenden
pkill -f "uvicorn"
```

## ğŸ“ˆ MLflow Tracking

Das Projekt verwendet MLflow fÃ¼r Experiment-Tracking:

- Embedding-Generierung wird automatisch getrackt
- Parameter und Metriken werden gespeichert
- Artefakte (CSV, Embeddings) werden geloggt

## ğŸ”„ Workflow

1. **Daten sammeln**: Reddit-Posts zu einer Aktie abrufen
2. **Embeddings generieren**: Posts in Vektoren umwandeln
3. **Vector Store**: Embeddings in Qdrant speichern
4. **RAG-Abfragen**: Ã„hnliche Posts finden und LLM-Antworten generieren
```
